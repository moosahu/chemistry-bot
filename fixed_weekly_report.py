#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Ù†Ø¸Ø§Ù… Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠØ© Ø§Ù„Ù…Ø­Ø³Ù† ÙˆØ§Ù„Ù…ØªÙƒØ§Ù…Ù„
ÙŠØ¹Ù…Ù„ Ù…Ø¹ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙ‚Ø· (pandas, matplotlib, openpyxl)
"""

import os
import logging
import smtplib
import schedule
import time
import threading
from datetime import datetime, timedelta
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.mime.base import MIMEBase
from email import encoders
from typing import Dict, List, Any, Optional, Tuple
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from sqlalchemy import create_engine, text
import json

logger = logging.getLogger(__name__)

class FixedWeeklyReportGenerator:
    """Ù…ÙˆÙ„Ø¯ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠØ© Ø§Ù„Ù…Ø­Ø³Ù†"""
    
    def __init__(self):
        """ØªÙ‡ÙŠØ¦Ø© Ù…ÙˆÙ„Ø¯ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ±"""
        self.database_url = os.getenv('DATABASE_URL')
        if not self.database_url:
            raise ValueError("Ù…ØªØºÙŠØ± DATABASE_URL ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")
        
        self.engine = create_engine(self.database_url)
        self.reports_dir = "fixed_reports"
        self.charts_dir = os.path.join(self.reports_dir, "charts")
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª
        os.makedirs(self.reports_dir, exist_ok=True)
        os.makedirs(self.charts_dir, exist_ok=True)
        
        logger.info(f"ØªÙ… Ø¥Ø¹Ø¯Ø§Ø¯ Ù…ÙˆÙ„Ø¯ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ù…Ø­Ø³Ù† - Ù…Ø¬Ù„Ø¯ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ±: {self.reports_dir}")
    
    def get_comprehensive_stats(self, start_date: datetime, end_date: datetime) -> Dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø´Ø§Ù…Ù„Ø©"""
        try:
            with self.engine.connect() as conn:
                # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†
                users_query = text("""
                    SELECT 
                        COUNT(*) as total_registered_users,
                        COUNT(CASE WHEN last_active_timestamp >= :start_date THEN 1 END) as active_users_this_week,
                        COUNT(CASE WHEN first_seen_timestamp >= :start_date THEN 1 END) as new_users_this_week
                    FROM users
                """)
                
                users_result = conn.execute(users_query, {
                    'start_date': start_date
                }).fetchone()
                
                # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
                quiz_query = text("""
                    SELECT 
                        COUNT(*) as total_quizzes_this_week,
                        COUNT(DISTINCT user_id) as unique_users_this_week,
                        AVG(percentage) as avg_percentage_this_week,
                        SUM(total_questions) as total_questions_this_week,
                        AVG(time_taken_seconds) as avg_time_taken
                    FROM quiz_results 
                    WHERE completed_at >= :start_date AND completed_at <= :end_date
                """)
                
                quiz_result = conn.execute(quiz_query, {
                    'start_date': start_date,
                    'end_date': end_date
                }).fetchone()
                
                # Ø­Ø³Ø§Ø¨ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù…Ø´Ø§Ø±ÙƒØ©
                total_users = users_result.total_registered_users or 0
                active_users = users_result.active_users_this_week or 0
                engagement_rate = (active_users / total_users * 100) if total_users > 0 else 0
                
                return {
                    'total_registered_users': total_users,
                    'active_users_this_week': active_users,
                    'new_users_this_week': users_result.new_users_this_week or 0,
                    'engagement_rate': round(engagement_rate, 2),
                    'total_quizzes_this_week': quiz_result.total_quizzes_this_week or 0,
                    'unique_users_this_week': quiz_result.unique_users_this_week or 0,
                    'avg_percentage_this_week': round(quiz_result.avg_percentage_this_week or 0, 2),
                    'total_questions_this_week': quiz_result.total_questions_this_week or 0,
                    'avg_time_taken': round(quiz_result.avg_time_taken or 0, 2)
                }
                
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø´Ø§Ù…Ù„Ø©: {e}")
            return {}
    
    def get_user_progress_analysis(self, start_date: datetime, end_date: datetime) -> List[Dict[str, Any]]:
        """ØªØ­Ù„ÙŠÙ„ ØªÙ‚Ø¯Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†"""
        try:
            with self.engine.connect() as conn:
                query = text("""
                    SELECT 
                        u.user_id,
                        u.username,
                        u.first_name,
                        u.last_name,
                        u.full_name,
                        u.grade,
                        u.first_seen_timestamp,
                        u.last_active_timestamp,
                        COUNT(qr.result_id) as total_quizzes,
                        AVG(qr.percentage) as overall_avg_percentage,
                        SUM(qr.total_questions) as total_questions_answered,
                        AVG(qr.time_taken_seconds) as avg_time_per_quiz,
                        MAX(qr.completed_at) as last_quiz_date,
                        MIN(qr.completed_at) as first_quiz_date
                    FROM users u
                    LEFT JOIN quiz_results qr ON u.user_id = qr.user_id 
                        AND qr.completed_at >= :start_date 
                        AND qr.completed_at <= :end_date
                    GROUP BY u.user_id, u.username, u.first_name, u.last_name, 
                             u.full_name, u.grade, u.first_seen_timestamp, u.last_active_timestamp
                    ORDER BY overall_avg_percentage DESC NULLS LAST
                """)
                
                result = conn.execute(query, {
                    'start_date': start_date,
                    'end_date': end_date
                }).fetchall()
                
                users_analysis = []
                for row in result:
                    # ØªØ­Ø¯ÙŠØ¯ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø£Ø¯Ø§Ø¡
                    avg_percentage = row.overall_avg_percentage or 0
                    if avg_percentage >= 90:
                        performance_level = "Ù…Ù…ØªØ§Ø²"
                    elif avg_percentage >= 80:
                        performance_level = "Ø¬ÙŠØ¯ Ø¬Ø¯Ø§Ù‹"
                    elif avg_percentage >= 70:
                        performance_level = "Ø¬ÙŠØ¯"
                    elif avg_percentage >= 60:
                        performance_level = "Ù…ØªÙˆØ³Ø·"
                    elif avg_percentage > 0:
                        performance_level = "Ø¶Ø¹ÙŠÙ"
                    else:
                        performance_level = "Ù„Ù… ÙŠØ´Ø§Ø±Ùƒ"
                    
                    # ØªØ­Ø¯ÙŠØ¯ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù†Ø´Ø§Ø·
                    total_quizzes = row.total_quizzes or 0
                    if total_quizzes >= 10:
                        activity_level = "Ù†Ø´Ø· Ø¬Ø¯Ø§Ù‹"
                    elif total_quizzes >= 5:
                        activity_level = "Ù†Ø´Ø·"
                    elif total_quizzes >= 1:
                        activity_level = "Ù‚Ù„ÙŠÙ„ Ø§Ù„Ù†Ø´Ø§Ø·"
                    else:
                        activity_level = "ØºÙŠØ± Ù†Ø´Ø·"
                    
                    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ (Ù…Ø¨Ø³Ø·)
                    trend = "Ø«Ø§Ø¨Øª"  # ÙŠÙ…ÙƒÙ† ØªØ­Ø³ÙŠÙ†Ù‡ Ù„Ø§Ø­Ù‚Ø§Ù‹ Ø¨ØªØ­Ù„ÙŠÙ„ Ø£Ø¹Ù…Ù‚
                    
                    users_analysis.append({
                        'user_id': row.user_id,
                        'username': row.username or 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯',
                        'full_name': row.full_name or f"{row.first_name or ''} {row.last_name or ''}".strip() or 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯',
                        'grade': row.grade or 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯',
                        'registration_date': row.first_seen_timestamp,
                        'last_active': row.last_active_timestamp,
                        'total_quizzes': total_quizzes,
                        'overall_avg_percentage': round(avg_percentage, 2),
                        'total_questions_answered': row.total_questions_answered or 0,
                        'avg_time_per_quiz': round(row.avg_time_per_quiz or 0, 2),
                        'performance_level': performance_level,
                        'activity_level': activity_level,
                        'trend': trend,
                        'last_quiz_date': row.last_quiz_date,
                        'first_quiz_date': row.first_quiz_date
                    })
                
                return users_analysis
                
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ ØªÙ‚Ø¯Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†: {e}")
            return []
    
    def get_grade_performance_analysis(self, start_date: datetime, end_date: datetime) -> List[Dict[str, Any]]:
        """ØªØ­Ù„ÙŠÙ„ Ø£Ø¯Ø§Ø¡ Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠØ©"""
        try:
            with self.engine.connect() as conn:
                query = text("""
                    SELECT 
                        u.grade,
                        COUNT(DISTINCT u.user_id) as total_students,
                        COUNT(qr.result_id) as total_quizzes,
                        AVG(qr.percentage) as avg_percentage,
                        COUNT(DISTINCT CASE WHEN qr.completed_at >= :start_date THEN u.user_id END) as active_students
                    FROM users u
                    LEFT JOIN quiz_results qr ON u.user_id = qr.user_id 
                        AND qr.completed_at >= :start_date 
                        AND qr.completed_at <= :end_date
                    WHERE u.grade IS NOT NULL AND u.grade != ''
                    GROUP BY u.grade
                    ORDER BY u.grade
                """)
                
                result = conn.execute(query, {
                    'start_date': start_date,
                    'end_date': end_date
                }).fetchall()
                
                grade_analysis = []
                for row in result:
                    participation_rate = (row.active_students / row.total_students * 100) if row.total_students > 0 else 0
                    
                    grade_analysis.append({
                        'grade': row.grade,
                        'total_students': row.total_students,
                        'active_students': row.active_students or 0,
                        'participation_rate': round(participation_rate, 2),
                        'total_quizzes': row.total_quizzes or 0,
                        'avg_percentage': round(row.avg_percentage or 0, 2)
                    })
                
                return grade_analysis
                
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø£Ø¯Ø§Ø¡ Ø§Ù„ØµÙÙˆÙ: {e}")
            return []
    
    def get_difficult_questions_analysis(self, start_date: datetime, end_date: datetime) -> List[Dict[str, Any]]:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ØµØ¹Ø¨Ø©"""
        try:
            with self.engine.connect() as conn:
                query = text("""
                    SELECT 
                        ua.question_id,
                        COUNT(*) as total_attempts,
                        SUM(CASE WHEN ua.is_correct THEN 1 ELSE 0 END) as correct_answers,
                        ROUND(
                            (SUM(CASE WHEN ua.is_correct THEN 1 ELSE 0 END)::float / COUNT(*)) * 100, 
                            2
                        ) as success_rate
                    FROM user_answers ua
                    WHERE ua.answer_time >= :start_date AND ua.answer_time <= :end_date
                    GROUP BY ua.question_id
                    HAVING COUNT(*) >= 5  -- Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„ 5 Ù…Ø­Ø§ÙˆÙ„Ø§Øª
                    ORDER BY success_rate ASC, total_attempts DESC
                    LIMIT 20
                """)
                
                result = conn.execute(query, {
                    'start_date': start_date,
                    'end_date': end_date
                }).fetchall()
                
                difficult_questions = []
                for row in result:
                    success_rate = row.success_rate or 0
                    
                    # ØªØ­Ø¯ÙŠØ¯ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØµØ¹ÙˆØ¨Ø©
                    if success_rate < 30:
                        difficulty_level = "ØµØ¹Ø¨ Ø¬Ø¯Ø§Ù‹"
                        priority = "Ø¹Ø§Ù„ÙŠØ©"
                    elif success_rate < 50:
                        difficulty_level = "ØµØ¹Ø¨"
                        priority = "Ù…ØªÙˆØ³Ø·Ø©"
                    elif success_rate < 70:
                        difficulty_level = "Ù…ØªÙˆØ³Ø·"
                        priority = "Ù…Ù†Ø®ÙØ¶Ø©"
                    else:
                        difficulty_level = "Ø³Ù‡Ù„"
                        priority = "Ù…Ù†Ø®ÙØ¶Ø©"
                    
                    difficult_questions.append({
                        'question_id': row.question_id,
                        'total_attempts': row.total_attempts,
                        'correct_answers': row.correct_answers,
                        'wrong_answers': row.total_attempts - row.correct_answers,
                        'success_rate': success_rate,
                        'difficulty_level': difficulty_level,
                        'review_priority': priority
                    })
                
                return difficult_questions
                
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ØµØ¹Ø¨Ø©: {e}")
            return []
    
    def get_time_patterns_analysis(self, start_date: datetime, end_date: datetime) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„ÙˆÙ‚Øª ÙˆØ§Ù„Ù†Ø´Ø§Ø·"""
        try:
            with self.engine.connect() as conn:
                # Ø§Ù„Ù†Ø´Ø§Ø· Ø§Ù„ÙŠÙˆÙ…ÙŠ
                daily_query = text("""
                    SELECT 
                        DATE(completed_at) as quiz_date,
                        COUNT(*) as quiz_count,
                        COUNT(DISTINCT user_id) as unique_users
                    FROM quiz_results
                    WHERE completed_at >= :start_date AND completed_at <= :end_date
                    GROUP BY DATE(completed_at)
                    ORDER BY quiz_date
                """)
                
                daily_result = conn.execute(daily_query, {
                    'start_date': start_date,
                    'end_date': end_date
                }).fetchall()
                
                # Ø§Ù„Ù†Ø´Ø§Ø· Ø­Ø³Ø¨ Ø§Ù„Ø³Ø§Ø¹Ø©
                hourly_query = text("""
                    SELECT 
                        EXTRACT(HOUR FROM completed_at) as hour,
                        COUNT(*) as quiz_count
                    FROM quiz_results
                    WHERE completed_at >= :start_date AND completed_at <= :end_date
                    GROUP BY EXTRACT(HOUR FROM completed_at)
                    ORDER BY quiz_count DESC
                    LIMIT 5
                """)
                
                hourly_result = conn.execute(hourly_query, {
                    'start_date': start_date,
                    'end_date': end_date
                }).fetchall()
                
                daily_activity = [
                    {
                        'date': row.quiz_date,
                        'quiz_count': row.quiz_count,
                        'unique_users': row.unique_users
                    }
                    for row in daily_result
                ]
                
                peak_hours = [
                    {
                        'hour': int(row.hour),
                        'quiz_count': row.quiz_count
                    }
                    for row in hourly_result
                ]
                
                return {
                    'daily_activity': daily_activity,
                    'peak_hours': peak_hours
                }
                
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„ÙˆÙ‚Øª: {e}")
            return {'daily_activity': [], 'peak_hours': []}
    
    def generate_smart_recommendations(self, general_stats: Dict, user_progress: List, 
                                     grade_analysis: List, difficult_questions: List, 
                                     time_patterns: Dict) -> Dict[str, List[str]]:
        """Ø¥Ù†Ø´Ø§Ø¡ ØªÙˆØµÙŠØ§Øª Ø°ÙƒÙŠØ©"""
        recommendations = {
            'Ù„Ù„Ø¥Ø¯Ø§Ø±Ø©': [],
            'Ù„Ù„Ù…Ø¹Ù„Ù…ÙŠÙ†': [],
            'Ù„Ù„Ù…Ø­ØªÙˆÙ‰': [],
            'Ù„Ù„Ù†Ø¸Ø§Ù…': []
        }
        
        try:
            # ØªÙˆØµÙŠØ§Øª Ù„Ù„Ø¥Ø¯Ø§Ø±Ø©
            engagement_rate = general_stats.get('engagement_rate', 0)
            if engagement_rate < 50:
                recommendations['Ù„Ù„Ø¥Ø¯Ø§Ø±Ø©'].append(f"Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù…Ø´Ø§Ø±ÙƒØ© Ù…Ù†Ø®ÙØ¶ ({engagement_rate}%). ÙŠÙÙ†ØµØ­ Ø¨Ø­Ù…Ù„Ø© ØªØ­ÙÙŠØ²ÙŠØ©")
            
            active_users = general_stats.get('active_users_this_week', 0)
            total_users = general_stats.get('total_registered_users', 0)
            if total_users > 0 and active_users / total_users < 0.3:
                recommendations['Ù„Ù„Ø¥Ø¯Ø§Ø±Ø©'].append("30% ÙÙ‚Ø· Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ù†Ø´Ø·ÙŠÙ†. ÙŠÙÙ†ØµØ­ Ø¨Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„ØªÙØ§Ø¹Ù„")
            
            # ØªÙˆØµÙŠØ§Øª Ù„Ù„Ù…Ø¹Ù„Ù…ÙŠÙ†
            weak_performers = [u for u in user_progress if u['performance_level'] in ['Ø¶Ø¹ÙŠÙ', 'Ù…ØªÙˆØ³Ø·']]
            if len(weak_performers) > len(user_progress) * 0.3:
                recommendations['Ù„Ù„Ù…Ø¹Ù„Ù…ÙŠÙ†'].append(f"{len(weak_performers)} Ù…Ø³ØªØ®Ø¯Ù… ÙŠØ­ØªØ§Ø¬ÙˆÙ† Ù…Ø³Ø§Ø¹Ø¯Ø© Ø¥Ø¶Ø§ÙÙŠØ©")
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ø¶Ø¹ÙŠÙØ©
            weak_grades = [g for g in grade_analysis if g['avg_percentage'] < 70]
            for grade in weak_grades:
                recommendations['Ù„Ù„Ù…Ø¹Ù„Ù…ÙŠÙ†'].append(f"Ø§Ù„ØµÙ {grade['grade']} ÙŠØ­ØªØ§Ø¬ ØªØ±ÙƒÙŠØ² Ø¥Ø¶Ø§ÙÙŠ (Ù…ØªÙˆØ³Ø·: {grade['avg_percentage']}%)")
            
            # ØªÙˆØµÙŠØ§Øª Ù„Ù„Ù…Ø­ØªÙˆÙ‰
            very_difficult = [q for q in difficult_questions if q['success_rate'] < 30]
            if very_difficult:
                recommendations['Ù„Ù„Ù…Ø­ØªÙˆÙ‰'].append(f"{len(very_difficult)} Ø³Ø¤Ø§Ù„ ØµØ¹Ø¨ Ø¬Ø¯Ø§Ù‹ ÙŠØ­ØªØ§Ø¬ Ù…Ø±Ø§Ø¬Ø¹Ø©")
            
            # ØªÙˆØµÙŠØ§Øª Ù„Ù„Ù†Ø¸Ø§Ù…
            avg_time = general_stats.get('avg_time_taken', 0)
            if avg_time > 300:  # Ø£ÙƒØ«Ø± Ù…Ù† 5 Ø¯Ù‚Ø§Ø¦Ù‚
                recommendations['Ù„Ù„Ù†Ø¸Ø§Ù…'].append("Ù…ØªÙˆØ³Ø· ÙˆÙ‚Øª Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ù…Ø±ØªÙØ¹. Ù‚Ø¯ ØªØ­ØªØ§Ø¬ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ØªØ¨Ø³ÙŠØ·")
            
            # ØªÙˆØµÙŠØ§Øª Ø§Ù„ÙˆÙ‚Øª
            peak_hours = time_patterns.get('peak_hours', [])
            if peak_hours:
                best_hour = peak_hours[0]['hour']
                recommendations['Ù„Ù„Ù†Ø¸Ø§Ù…'].append(f"Ø£ÙØ¶Ù„ ÙˆÙ‚Øª Ù„Ù„Ù†Ø´Ø§Ø·: Ø§Ù„Ø³Ø§Ø¹Ø© {best_hour}:00. ÙŠÙÙ†ØµØ­ Ø¨Ø¬Ø¯ÙˆÙ„Ø© Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¬Ø¯ÙŠØ¯")
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø°ÙƒÙŠØ©: {e}")
        
        return recommendations
    
    def create_performance_charts(self, user_progress: List, grade_analysis: List, 
                                time_patterns: Dict) -> Dict[str, str]:
        """Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ©"""
        chart_paths = {}
        
        try:
            # Ø¥Ø¹Ø¯Ø§Ø¯ matplotlib Ù„Ù„Ø¹Ø±Ø¨ÙŠØ©
            plt.rcParams['font.family'] = ['Arial Unicode MS', 'Tahoma', 'DejaVu Sans']
            
            # 1. ØªÙˆØ²ÙŠØ¹ Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡
            if user_progress:
                performance_counts = {}
                for user in user_progress:
                    level = user['performance_level']
                    performance_counts[level] = performance_counts.get(level, 0) + 1
                
                if performance_counts:
                    fig, ax = plt.subplots(figsize=(10, 6))
                    levels = list(performance_counts.keys())
                    counts = list(performance_counts.values())
                    colors = ['#2E8B57', '#32CD32', '#FFD700', '#FF6347', '#DC143C', '#808080']
                    
                    bars = ax.bar(levels, counts, color=colors[:len(levels)])
                    ax.set_title('ØªÙˆØ²ÙŠØ¹ Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡', fontsize=16, fontweight='bold')
                    ax.set_ylabel('Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†', fontsize=12)
                    ax.set_xlabel('Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø£Ø¯Ø§Ø¡', fontsize=12)
                    
                    # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù‚ÙŠÙ… Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
                    for bar, count in zip(bars, counts):
                        height = bar.get_height()
                        ax.text(bar.get_x() + bar.get_width()/2., height + 0.1,
                               f'{count}', ha='center', va='bottom', fontweight='bold')
                    
                    plt.xticks(rotation=45)
                    plt.tight_layout()
                    
                    chart_path = os.path.join(self.charts_dir, 'performance_distribution.png')
                    plt.savefig(chart_path, dpi=300, bbox_inches='tight')
                    plt.close()
                    chart_paths['ØªÙˆØ²ÙŠØ¹ Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡'] = chart_path
            
            # 2. Ù…Ù‚Ø§Ø±Ù†Ø© Ø£Ø¯Ø§Ø¡ Ø§Ù„ØµÙÙˆÙ
            if grade_analysis:
                fig, ax = plt.subplots(figsize=(12, 6))
                grades = [g['grade'] for g in grade_analysis]
                percentages = [g['avg_percentage'] for g in grade_analysis]
                
                bars = ax.bar(grades, percentages, color='#4CAF50')
                ax.set_title('Ù…ØªÙˆØ³Ø· Ø£Ø¯Ø§Ø¡ Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠØ©', fontsize=16, fontweight='bold')
                ax.set_ylabel('Ù…ØªÙˆØ³Ø· Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø¦ÙˆÙŠØ© (%)', fontsize=12)
                ax.set_xlabel('Ø§Ù„ØµÙ Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠ', fontsize=12)
                ax.set_ylim(0, 100)
                
                # Ø¥Ø¶Ø§ÙØ© Ø®Ø· Ø§Ù„Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¹Ø§Ù…
                overall_avg = sum(percentages) / len(percentages) if percentages else 0
                ax.axhline(y=overall_avg, color='red', linestyle='--', 
                          label=f'Ø§Ù„Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¹Ø§Ù…: {overall_avg:.1f}%')
                ax.legend()
                
                # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù‚ÙŠÙ… Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
                for bar, percentage in zip(bars, percentages):
                    height = bar.get_height()
                    ax.text(bar.get_x() + bar.get_width()/2., height + 1,
                           f'{percentage:.1f}%', ha='center', va='bottom', fontweight='bold')
                
                plt.xticks(rotation=45)
                plt.tight_layout()
                
                chart_path = os.path.join(self.charts_dir, 'grade_performance.png')
                plt.savefig(chart_path, dpi=300, bbox_inches='tight')
                plt.close()
                chart_paths['Ø£Ø¯Ø§Ø¡ Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠØ©'] = chart_path
            
            # 3. Ø§Ù„Ù†Ø´Ø§Ø· Ø§Ù„ÙŠÙˆÙ…ÙŠ
            daily_activity = time_patterns.get('daily_activity', [])
            if daily_activity:
                fig, ax = plt.subplots(figsize=(12, 6))
                dates = [activity['date'] for activity in daily_activity]
                counts = [activity['quiz_count'] for activity in daily_activity]
                
                ax.plot(dates, counts, marker='o', linewidth=2, markersize=6, color='#2196F3')
                ax.fill_between(dates, counts, alpha=0.3, color='#2196F3')
                
                ax.set_title('Ø§Ù„Ù†Ø´Ø§Ø· Ø§Ù„ÙŠÙˆÙ…ÙŠ Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª', fontsize=16, fontweight='bold')
                ax.set_ylabel('Ø¹Ø¯Ø¯ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª', fontsize=12)
                ax.set_xlabel('Ø§Ù„ØªØ§Ø±ÙŠØ®', fontsize=12)
                
                # ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®
                ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))
                ax.xaxis.set_major_locator(mdates.DayLocator(interval=1))
                
                plt.xticks(rotation=45)
                plt.grid(True, alpha=0.3)
                plt.tight_layout()
                
                chart_path = os.path.join(self.charts_dir, 'daily_activity.png')
                plt.savefig(chart_path, dpi=300, bbox_inches='tight')
                plt.close()
                chart_paths['Ø§Ù„Ù†Ø´Ø§Ø· Ø§Ù„ÙŠÙˆÙ…ÙŠ'] = chart_path
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ©: {e}")
        
        return chart_paths
    
    def create_fixed_excel_report(self, start_date: datetime, end_date: datetime) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Excel Ù…Ø­Ø³Ù†"""
        try:
            # Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            general_stats = self.get_comprehensive_stats(start_date, end_date)
            user_progress = self.get_user_progress_analysis(start_date, end_date)
            grade_analysis = self.get_grade_performance_analysis(start_date, end_date)
            difficult_questions = self.get_difficult_questions_analysis(start_date, end_date)
            time_patterns = self.get_time_patterns_analysis(start_date, end_date)
            smart_recommendations = self.generate_smart_recommendations(
                general_stats, user_progress, grade_analysis, difficult_questions, time_patterns
            )
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ©
            chart_paths = self.create_performance_charts(user_progress, grade_analysis, time_patterns)
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Excel
            report_filename = f"fixed_weekly_report_{start_date.strftime('%Y-%m-%d')}.xlsx"
            report_path = os.path.join(self.reports_dir, report_filename)
            
            with pd.ExcelWriter(report_path, engine='openpyxl') as writer:
                # 1. Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠ
                executive_summary = pd.DataFrame([
                    ['Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø§Ù„Ù…Ø³Ø¬Ù„ÙŠÙ†', general_stats.get('total_registered_users', 0)],
                    ['Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø§Ù„Ù†Ø´Ø·ÙŠÙ† Ù‡Ø°Ø§ Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹', general_stats.get('active_users_this_week', 0)],
                    ['Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø§Ù„Ø¬Ø¯Ø¯', general_stats.get('new_users_this_week', 0)],
                    ['Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù…Ø´Ø§Ø±ÙƒØ© (%)', general_stats.get('engagement_rate', 0)],
                    ['Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª', general_stats.get('total_quizzes_this_week', 0)],
                    ['Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¯Ø±Ø¬Ø§Øª (%)', general_stats.get('avg_percentage_this_week', 0)],
                    ['Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…Ø¬Ø§Ø¨Ø©', general_stats.get('total_questions_this_week', 0)],
                    ['Ù…ØªÙˆØ³Ø· Ø§Ù„ÙˆÙ‚Øª (Ø«Ø§Ù†ÙŠØ©)', general_stats.get('avg_time_taken', 0)]
                ], columns=['Ø§Ù„Ù…Ø¤Ø´Ø±', 'Ø§Ù„Ù‚ÙŠÙ…Ø©'])
                
                executive_summary.to_excel(writer, sheet_name='Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠ', index=False)
                
                # 2. ØªÙ‚Ø¯Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†
                if user_progress:
                    users_df = pd.DataFrame(user_progress)
                    users_df.to_excel(writer, sheet_name='ØªÙ‚Ø¯Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†', index=False)
                
                # 3. Ø£Ø¯Ø§Ø¡ Ø§Ù„ØµÙÙˆÙ
                if grade_analysis:
                    grades_df = pd.DataFrame(grade_analysis)
                    grades_df.to_excel(writer, sheet_name='Ø£Ø¯Ø§Ø¡ Ø§Ù„ØµÙÙˆÙ', index=False)
                
                # 4. Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ØµØ¹Ø¨Ø©
                if difficult_questions:
                    questions_df = pd.DataFrame(difficult_questions)
                    questions_df.to_excel(writer, sheet_name='Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ØµØ¹Ø¨Ø©', index=False)
                
                # 5. Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù†Ø´Ø§Ø·
                if time_patterns.get('daily_activity'):
                    daily_df = pd.DataFrame(time_patterns['daily_activity'])
                    daily_df.to_excel(writer, sheet_name='Ø§Ù„Ù†Ø´Ø§Ø· Ø§Ù„ÙŠÙˆÙ…ÙŠ', index=False)
                
                if time_patterns.get('peak_hours'):
                    hourly_df = pd.DataFrame(time_patterns['peak_hours'])
                    hourly_df.to_excel(writer, sheet_name='Ø³Ø§Ø¹Ø§Øª Ø§Ù„Ø°Ø±ÙˆØ©', index=False)
                
                # 6. Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø°ÙƒÙŠØ©
                recommendations_data = []
                for category, recs in smart_recommendations.items():
                    for rec in recs:
                        recommendations_data.append([category, rec])
                
                if recommendations_data:
                    recommendations_df = pd.DataFrame(recommendations_data, columns=['Ø§Ù„ÙØ¦Ø©', 'Ø§Ù„ØªÙˆØµÙŠØ©'])
                    recommendations_df.to_excel(writer, sheet_name='Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø°ÙƒÙŠØ©', index=False)
            
            logger.info(f"ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…Ø­Ø³Ù†: {report_path}")
            return report_path
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Excel Ø§Ù„Ù…Ø­Ø³Ù†: {e}")
            return None
    
    def send_email_report(self, report_path: str, chart_paths: Dict[str, str], 
                         start_date: datetime, end_date: datetime) -> bool:
        """Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø¨Ø§Ù„Ø¥ÙŠÙ…ÙŠÙ„"""
        try:
            # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¥ÙŠÙ…ÙŠÙ„
            smtp_server = "smtp.gmail.com"
            smtp_port = 587
            sender_email = os.getenv('EMAIL_USERNAME')
            sender_password = os.getenv('EMAIL_PASSWORD')
            admin_email = os.getenv('ADMIN_EMAIL')
            
            if not all([sender_email, sender_password, admin_email]):
                logger.error("Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¥ÙŠÙ…ÙŠÙ„ ØºÙŠØ± Ù…ÙƒØªÙ…Ù„Ø©")
                return False
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø±Ø³Ø§Ù„Ø©
            msg = MIMEMultipart()
            msg['From'] = sender_email
            msg['To'] = admin_email
            msg['Subject'] = f"Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠ Ø§Ù„Ù…Ø­Ø³Ù† - {start_date.strftime('%Y-%m-%d')} Ø¥Ù„Ù‰ {end_date.strftime('%Y-%m-%d')}"
            
            # Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø±Ø³Ø§Ù„Ø©
            body = f"""
Ù…Ø±Ø­Ø¨Ø§Ù‹ØŒ

Ø¥Ù„ÙŠÙƒ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠ Ø§Ù„Ù…Ø­Ø³Ù† Ù„Ø¨ÙˆØª Ø§Ù„ÙƒÙŠÙ…ÙŠØ§Ø¡ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ.

ğŸ“Š ÙØªØ±Ø© Ø§Ù„ØªÙ‚Ø±ÙŠØ±: {start_date.strftime('%Y-%m-%d')} Ø¥Ù„Ù‰ {end_date.strftime('%Y-%m-%d')}

ğŸ“‹ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØªÙ‚Ø±ÙŠØ±:
â€¢ Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠ Ù…Ø¹ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
â€¢ ØªØ­Ù„ÙŠÙ„ Ù…ÙØµÙ„ Ù„ØªÙ‚Ø¯Ù… ÙƒÙ„ Ù…Ø³ØªØ®Ø¯Ù…
â€¢ Ø£Ø¯Ø§Ø¡ Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠØ© Ù…Ø¹ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø§Øª
â€¢ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ØµØ¹Ø¨Ø© Ø§Ù„ØªÙŠ ØªØ­ØªØ§Ø¬ Ù…Ø±Ø§Ø¬Ø¹Ø©
â€¢ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù†Ø´Ø§Ø· ÙˆØ§Ù„Ø£ÙˆÙ‚Ø§Øª Ø§Ù„Ù…Ø«Ù„Ù‰
â€¢ ØªÙˆØµÙŠØ§Øª Ø°ÙƒÙŠØ© Ù„Ù„ØªØ­Ø³ÙŠÙ†

ğŸ“ˆ Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ© Ø§Ù„Ù…Ø±ÙÙ‚Ø©:
{chr(10).join([f"â€¢ {name}" for name in chart_paths.keys()])}

Ù…Ø¹ Ø£Ø·ÙŠØ¨ Ø§Ù„ØªØ­ÙŠØ§ØªØŒ
Ù†Ø¸Ø§Ù… Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ù…Ø­Ø³Ù†
            """
            
            msg.attach(MIMEText(body, 'plain', 'utf-8'))
            
            # Ø¥Ø±ÙØ§Ù‚ Ù…Ù„Ù Excel
            if report_path and os.path.exists(report_path):
                with open(report_path, "rb") as attachment:
                    part = MIMEBase('application', 'octet-stream')
                    part.set_payload(attachment.read())
                    encoders.encode_base64(part)
                    part.add_header(
                        'Content-Disposition',
                        f'attachment; filename= {os.path.basename(report_path)}'
                    )
                    msg.attach(part)
            
            # Ø¥Ø±ÙØ§Ù‚ Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ©
            for chart_name, chart_path in chart_paths.items():
                if os.path.exists(chart_path):
                    with open(chart_path, "rb") as attachment:
                        part = MIMEBase('application', 'octet-stream')
                        part.set_payload(attachment.read())
                        encoders.encode_base64(part)
                        part.add_header(
                            'Content-Disposition',
                            f'attachment; filename= {chart_name}.png'
                        )
                        msg.attach(part)
            
            # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø¥ÙŠÙ…ÙŠÙ„
            server = smtplib.SMTP(smtp_server, smtp_port)
            server.starttls()
            server.login(sender_email, sender_password)
            text = msg.as_string()
            server.sendmail(sender_email, admin_email, text)
            server.quit()
            
            logger.info(f"ØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…Ø­Ø³Ù† Ø¨Ù†Ø¬Ø§Ø­ Ø¥Ù„Ù‰ {admin_email}")
            return True
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…Ø­Ø³Ù†: {e}")
            return False
    
    def generate_and_send_fixed_report(self) -> bool:
        """Ø¥Ù†Ø´Ø§Ø¡ ÙˆØ¥Ø±Ø³Ø§Ù„ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…Ø­Ø³Ù†"""
        try:
            # ØªØ­Ø¯ÙŠØ¯ ÙØªØ±Ø© Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ Ø§Ù„Ù…Ø§Ø¶ÙŠ
            today = datetime.now()
            end_date = today - timedelta(days=today.weekday() + 1)  # Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ Ø§Ù„Ù…Ø§Ø¶ÙŠ
            start_date = end_date - timedelta(days=6)  # Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ Ø§Ù„Ù…Ø§Ø¶ÙŠ
            
            # ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø£ÙˆÙ‚Ø§Øª
            start_date = start_date.replace(hour=0, minute=0, second=0, microsecond=0)
            end_date = end_date.replace(hour=23, minute=59, second=59, microsecond=999999)
            
            logger.info(f"Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…Ø­Ø³Ù† Ù„Ù„ÙØªØ±Ø©: {start_date} Ø¥Ù„Ù‰ {end_date}")
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
            report_path = self.create_fixed_excel_report(start_date, end_date)
            if not report_path:
                logger.error("ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…Ø­Ø³Ù†")
                return False
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ©
            user_progress = self.get_user_progress_analysis(start_date, end_date)
            grade_analysis = self.get_grade_performance_analysis(start_date, end_date)
            time_patterns = self.get_time_patterns_analysis(start_date, end_date)
            chart_paths = self.create_performance_charts(user_progress, grade_analysis, time_patterns)
            
            # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
            success = self.send_email_report(report_path, chart_paths, start_date, end_date)
            
            if success:
                logger.info("ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ ÙˆØ¥Ø±Ø³Ø§Ù„ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…Ø­Ø³Ù† Ø¨Ù†Ø¬Ø§Ø­")
            else:
                logger.error("ÙØ´Ù„ ÙÙŠ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…Ø­Ø³Ù†")
            
            return success
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ ÙˆØ¥Ø±Ø³Ø§Ù„ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…Ø­Ø³Ù†: {e}")
            return False

class FixedWeeklyReportScheduler:
    """Ø¬Ø¯ÙˆÙ„Ø© Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠØ© Ø§Ù„Ù…Ø­Ø³Ù†Ø©"""
    
    def __init__(self, report_generator: FixedWeeklyReportGenerator):
        self.report_generator = report_generator
        self.scheduler_thread = None
        self.running = False
    
    def start_scheduler(self):
        """Ø¨Ø¯Ø¡ Ø¬Ø¯ÙˆÙ„Ø© Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ±"""
        try:
            # Ø¬Ø¯ÙˆÙ„Ø© Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠ (ÙƒÙ„ ÙŠÙˆÙ… Ø£Ø­Ø¯ Ø§Ù„Ø³Ø§Ø¹Ø© 9:00 ØµØ¨Ø§Ø­Ø§Ù‹)
            schedule.every().sunday.at("09:00").do(self._run_weekly_report)
            
            self.running = True
            self.scheduler_thread = threading.Thread(target=self._run_scheduler, daemon=True)
            self.scheduler_thread.start()
            
            logger.info("ØªÙ… Ø¨Ø¯Ø¡ Ø¬Ø¯ÙˆÙ„Ø© Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ù…Ø­Ø³Ù†Ø© - ÙƒÙ„ ÙŠÙˆÙ… Ø£Ø­Ø¯ Ø§Ù„Ø³Ø§Ø¹Ø© 9:00 ØµØ¨Ø§Ø­Ø§Ù‹")
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¨Ø¯Ø¡ Ø¬Ø¯ÙˆÙ„Ø© Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ù…Ø­Ø³Ù†Ø©: {e}")
    
    def _run_scheduler(self):
        """ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¬Ø¯ÙˆÙ„Ø©"""
        while self.running:
            try:
                schedule.run_pending()
                time.sleep(60)  # ÙØ­Øµ ÙƒÙ„ Ø¯Ù‚ÙŠÙ‚Ø©
            except Exception as e:
                logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ´ØºÙŠÙ„ Ø¬Ø¯ÙˆÙ„Ø© Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ù…Ø­Ø³Ù†Ø©: {e}")
                time.sleep(60)
    
    def _run_weekly_report(self):
        """ØªØ´ØºÙŠÙ„ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠ"""
        try:
            logger.info("Ø¨Ø¯Ø¡ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠ Ø§Ù„Ù…Ø­Ø³Ù† Ø§Ù„Ù…Ø¬Ø¯ÙˆÙ„...")
            success = self.report_generator.generate_and_send_fixed_report()
            
            if success:
                logger.info("ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ ÙˆØ¥Ø±Ø³Ø§Ù„ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠ Ø§Ù„Ù…Ø­Ø³Ù† Ø§Ù„Ù…Ø¬Ø¯ÙˆÙ„ Ø¨Ù†Ø¬Ø§Ø­")
            else:
                logger.error("ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠ Ø§Ù„Ù…Ø­Ø³Ù† Ø§Ù„Ù…Ø¬Ø¯ÙˆÙ„")
                
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠ Ø§Ù„Ù…Ø­Ø³Ù† Ø§Ù„Ù…Ø¬Ø¯ÙˆÙ„: {e}")
    
    def stop_scheduler(self):
        """Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø¬Ø¯ÙˆÙ„Ø©"""
        self.running = False
        if self.scheduler_thread:
            self.scheduler_thread.join(timeout=5)
        logger.info("ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø¬Ø¯ÙˆÙ„Ø© Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ù…Ø­Ø³Ù†Ø©")

def is_fixed_email_configured() -> bool:
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¥ÙŠÙ…ÙŠÙ„ Ø§Ù„Ù…Ø­Ø³Ù†Ø©"""
    required_vars = ['EMAIL_USERNAME', 'EMAIL_PASSWORD', 'ADMIN_EMAIL']
    return all(os.getenv(var) for var in required_vars)

